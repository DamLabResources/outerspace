# OUTERSPACE Pipeline Configuration for SIV Barcoding Analysis
# This configuration file defines inputs and parameters for the Snakemake workflow

# TOML configuration file containing patterns and command parameters
toml: "sivbarcode.toml"

# Input data specification
# Method 1: Directory-based input (recommended for this tutorial)
direc: "data"
paired: false  # BAM files are single-end reads

# Method 2: Sample sheet (alternative - uncomment to use)
# samples: "samplesheet.csv"

# Output sample names (optional - will use filenames if not specified)
# These names will be used in output file naming
sample_names:
  - "Early_Timepoint"
  - "Later_Timepoint"

# Pipeline execution parameters
cores: 4              # Number of CPU cores to use locally
executor: "local"     # Execution backend: local, slurm, cluster

# Resource specifications for each rule
# These are especially useful for cluster execution
resources:
  findseq:
    threads: 2        # CPU threads per job
    mem_mb: 4000      # Memory in megabytes
    time: "02:00:00"  # Wall time (HH:MM:SS)
    partition: "compute"  # Cluster partition (SLURM)
  
  collapse:
    threads: 1
    mem_mb: 2000
    time: "01:00:00"
    partition: "compute"
  
  count:
    threads: 1
    mem_mb: 1000
    time: "00:30:00"
    partition: "compute"
  
  merge:
    threads: 1
    mem_mb: 1000
    time: "00:15:00"
    partition: "compute"
  
  stats:
    threads: 1
    mem_mb: 1000
    time: "00:15:00"
    partition: "compute"

# Cluster-specific settings (for SLURM)
cluster:
  account: "myproject"     # Project account for billing
  partition: "compute"     # Default partition
  qos: "normal"           # Quality of service
  
# Advanced pipeline options
pipeline_options:
  keep_temp: false        # Keep temporary files
  benchmark: false        # Enable benchmarking
  conda: false           # Use conda environments
  singularity: false     # Use Singularity containers
